# Llamabase

Llamabase is an elegant Go web framework inspired by Laravel, designed for modern AI-powered development. Built with clean architecture principles and offering intuitive APIs similar to Laravel's elegance.

## ğŸš€ Quick Start - Project Information

è®¿é—®æ ¹è·¯å¾„è·å–é¡¹ç›®å®Œæ•´ä¿¡æ¯ï¼š

```bash
curl http://localhost:6066/
```

è¿”å›æ ¼å¼ï¼š
```json
{
  "success": true,
  "message": "Welcome to Llamabase API",
  "data": {
    "name": "Llamabase",
    "description": "A comprehensive REST API service built with Go and Gin framework...",
    "version": "v1.0.0",
    "go_version": "1.23.0+",
    "build_time": "2025-06-19 19:01:55",
    "environment": "debug",
    "api": {
      "version": "v1",
      "base_url": "/v1",
      "endpoints": [
        "POST /v1/register - User registration",
        "POST /v1/login - User login",
        "GET /v1/users/profile - Get user profile",
        "POST /v1/organizations - Create organization",
        "GET /v1/organizations - List organizations",
        "POST /v1/teams - Create team",
        "GET /v1/teams/:id - Get team details",
        "POST /v1/apikeys - Create API key",
        "GET /v1/apikeys - List API keys"
      ],
      "features": [
        "JWT Authentication",
        "API Key Authentication",
        "User Management",
        "Organization Management",
        "Team Management",
        "Role-based Access Control",
        "Email Notifications",
        "PostgreSQL Database",
        "Docker Support",
        "Swagger Documentation"
      ]
    },
    "links": {
      "documentation": "/swagger/index.html",
      "health": "/v1/health/status",
      "swagger": "/swagger/*any"
    }
  }
}
```

## ğŸ¯ API å…¥å£ç‚¹

| ç«¯ç‚¹ | æè¿° | ç”¨é€” |
|------|------|------|
| `GET /` | é¡¹ç›®ä¿¡æ¯å’ŒAPIæ¦‚è§ˆ | äº†è§£é¡¹ç›®åŠŸèƒ½å’Œå¯ç”¨æ¥å£ |
| `GET /ping` | ç®€å•å¥åº·æ£€æŸ¥ | å¿«é€ŸéªŒè¯æœåŠ¡çŠ¶æ€ |
| `GET /v1/health/status` | è¯¦ç»†å¥åº·çŠ¶æ€ | å®Œæ•´çš„æœåŠ¡å¥åº·æ£€æŸ¥ |
| `GET /swagger/index.html` | APIæ–‡æ¡£ | å®Œæ•´çš„APIæ–‡æ¡£å’Œæµ‹è¯•ç•Œé¢ |

## Features

- ğŸ“¦ Modular architecture designed for AI coding
- ğŸ¤– Built-in LLM API integrations (OpenAI, Claude, etc.)
- ğŸ” JWT authentication with AI-enhanced security
- ğŸ“ Auto-generated Swagger API documentation
- ğŸš¦ Intelligent rate limiting
- ğŸ“¨ Asynchronous task queue for AI workflows
- ğŸ”„ WebSocket support for real-time AI interactions
- ğŸ“Š GORM database operations with AI query optimization
- ğŸ’¾ Redis cache optimized for LLM responses
- ğŸ“§ Smart email service with AI templates
- ğŸ” Unified error handling with AI diagnostics
- ğŸ“ Structured logging (Zap) for AI debugging
- âš™ï¸ Configuration management optimized for AI services
- ğŸ¯ Agent-based architecture support
- ğŸ§  Ready-to-use AI prompt templates
- ğŸ”„ Streaming response support for LLM interactions

## Quick Start

### Requirements

- Go 1.21+
- PostgreSQL 12+
- Redis 6.0+
- OpenAI API Key (or other LLM provider)

### Installation

```bash
git clone https://github.com/llamacto/llamabase.git
cd llamabase
go mod download
```

### Configuration

1. Copy the environment variable template:
```bash
cp .env.example .env
```

2. Configure your LLM API keys and other services in `.env`:
```bash
# LLM Configuration
OPENAI_API_KEY=your_openai_api_key
# Add other LLM providers as needed

# Database
DB_USERNAME=your_db_username
DB_PASSWORD=your_db_password
DB_NAME=llama_gin_kit

# JWT for AI-enhanced auth
JWT_SECRET=your_jwt_secret

# Other services...
```

3. Copy the config file template (if available):
```bash
cp config/config.example.yaml config/config.yaml
```

4. (Optional) Cache configuration for faster boots.
```bash
go run cmd/tools/main.go -tool=config-cache
```
This writes a snapshot to `storage/framework/cache/config.json`. Remove it with `go run cmd/tools/main.go -tool=config-clear` whenever `.env` changes.

5. (Optional) Skip database initialization in local or CI smoke tests:
```bash
export DB_ENABLED=false
```
When disabled, the HTTP server starts without touching Postgresâ€”ideal for lightweight checks.

### Run

```bash
# Run database migration
make migrate

# Start the AI-powered service
make run
```

## Project Structure

```
llamabase/
â”œâ”€â”€ cmd/                   # Entry files (server, migrate, tools, etc.)
â”œâ”€â”€ app/                   # Business modules (user, ai-agents, etc.)
â”‚   â”œâ”€â”€ user/             # User management
â”‚   â””â”€â”€ agents/           # AI agent implementations
â”œâ”€â”€ config/               # Configuration management
â”œâ”€â”€ middleware/           # Gin middleware (including AI middleware)
â”œâ”€â”€ pkg/                  # Utility packages
â”‚   â”œâ”€â”€ ai/              # AI service integrations
â”‚   â”œâ”€â”€ container/       # Lightweight IoC container
â”‚   â”œâ”€â”€ llm/             # LLM client implementations
â”‚   â””â”€â”€ agents/          # Agent framework
â”œâ”€â”€ routes/               # Route management
â”œâ”€â”€ storage/              # Static/persistent resources
â”œâ”€â”€ docs/                 # API documentation
â””â”€â”€ templates/            # AI prompt templates
```

## AI Features

### LLM Integration

The kit comes with built-in support for multiple LLM providers:

- **OpenAI GPT models** (GPT-4, GPT-3.5-turbo)
- **Streaming responses** for real-time AI interactions
- **Prompt template management** for consistent AI outputs
- **Token usage tracking** and cost optimization

### Agent-Based Architecture

Build sophisticated AI agents with:

- **Multi-step reasoning** workflows
- **Tool integration** for external API calls
- **Memory management** for context retention
- **Parallel processing** for complex tasks

### AI-Enhanced APIs

- **Intelligent text processing** endpoints
- **Automated content generation** services
- **Real-time language translation** with context awareness
- **Smart data analysis** and insights generation

## Development Guide

### Add a New AI Module

1. Create a new module directory under `app/`
2. Implement model, repository, service, and handler with AI integration
3. Add LLM-specific functionality in `pkg/ai/`
4. Register routes in `routes/` with appropriate middleware

### Add Custom LLM Provider

1. Implement the LLM interface in `pkg/llm/`
2. Add configuration in `config/`
3. Register the provider in your service initialization

### Run Tests

```bash
make test
```

### Generate API Documentation

```bash
make swagger
```

## Environment Variables

All sensitive information, secrets, and API keys are configured via the `.env` file. Do not commit real secrets to the repository; only commit `.env.example`.

Critical environment variables for AI features:
```bash
# LLM APIs
OPENAI_API_KEY=<your-openai-api-key>
ANTHROPIC_API_KEY=<your-anthropic-api-key>

# Database
DB_USERNAME=<your-db-username>
DB_PASSWORD=<your-db-password>
DB_NAME=llama_gin_kit

# Security
JWT_SECRET=<your-jwt-secret>

# Redis for caching LLM responses
REDIS_HOST=localhost
REDIS_PASSWORD=<your-redis-password>
```

## Deployment

### Docker

```bash
# Build the AI-powered image
docker build -t llama-gin-kit .

# Run the container with AI services
docker run -p 8080:8080 -e OPENAI_API_KEY=your_key llama-gin-kit
```

### Production Considerations

- Use environment variables for all LLM API keys
- Configure proper rate limiting for AI endpoints
- Set up monitoring for LLM usage and costs
- Implement proper error handling for AI service failures

## AI Coding Optimizations

This scaffold is specifically optimized for AI-assisted development:

- **Cursor IDE integration** with proper .cursorrules
- **Windsurf conventions** for seamless AI coding
- **Automated test generation** templates
- **AI-friendly code structure** for better LLM understanding
- **Built-in prompt engineering** utilities

## Contributing

Pull requests and issues are welcome! This project is designed to evolve with the AI coding ecosystem.

## License

MIT License

---

Built with â¤ï¸ for elegant Go development. Inspired by Laravel, optimized for modern workflows. 
